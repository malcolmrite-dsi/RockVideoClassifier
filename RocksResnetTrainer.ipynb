{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RocksResnetTrainer",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malcolmrite-dsi/RockVideoClassifier/blob/main/RocksResnetTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcruEbiWvZ43",
        "outputId": "f86b8db3-5e11-46fd-f2fd-9f7627f2225e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSG4gi0zxw2C"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten, Dropout\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from tensorflow.keras.applications import xception\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zaxYATlE01Q"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21-3DwUHHobs",
        "outputId": "949bf127-3655-4561-d29f-3a51470dc645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(validation_split=0.2, preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/Module 2 shared folder/samples',\n",
        "        subset=\"training\",\n",
        "        seed=3,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory( '/content/drive/My Drive/Module 2 shared folder/samples', \n",
        "        subset=\"validation\",\n",
        "        seed=3,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3132 images belonging to 5 classes.\n",
            "Found 781 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hksB_72TY-Ls",
        "outputId": "d97aa42c-2761-454a-a352-bdd2552218e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/Module 2 shared folder/samples',\n",
        "        subset=\"training\",\n",
        "        seed=3,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3913 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xATOlSeOUaz"
      },
      "source": [
        "resnet = keras.applications.ResNet50(include_top=False, pooling=\"max\", input_shape=(64,64,3))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DothacpCQIN6"
      },
      "source": [
        "# mark loaded layers as not trainable\n",
        "for layer in resnet.layers:\n",
        "  layer.trainable = False \n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pm0ce-m0PgR"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  #keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIDhw6JqQNCn"
      },
      "source": [
        "# mark loaded layers as not trainable\n",
        "#for layer in resnet.layers:\n",
        "\t#layer.trainable = False \n",
        "    \n",
        "flat = Flatten()(resnet.layers[-1].output)\n",
        "dense = Dense(1024, activation='relu')(flat)\n",
        "output = Dense(5, activation='softmax')(dense)\n",
        "model = Model(inputs=resnet.inputs, outputs=output)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV4cK0F_y7uj"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWcigw5IJQcL",
        "outputId": "f4e8a991-e40c-4f7c-9e2a-e845ad416681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=[\"categorical_accuracy\"])\n",
        "checkpoint_best = keras.callbacks.ModelCheckpoint(\"/content/drive/My Drive/model_best.h5\", \n",
        "            monitor='loss', verbose=0, save_best_only=True, save_weights_only=False, save_freq='epoch')\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\"/content/drive/My Drive/model_last.h5\", \n",
        "            verbose=0, save_best_only=False, save_weights_only=False, save_freq='epoch')\n",
        "model.fit(\n",
        "        train_generator,\n",
        "        epochs = 3,\n",
        "        validation_data=val_generator,\n",
        "        callbacks=[checkpoint_best]\n",
        ")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "49/49 [==============================] - 61s 1s/step - loss: 1.3357 - categorical_accuracy: 0.7995 - val_loss: 0.8146 - val_categorical_accuracy: 0.8707\n",
            "Epoch 2/3\n",
            "49/49 [==============================] - 61s 1s/step - loss: 0.3326 - categorical_accuracy: 0.8994 - val_loss: 0.7233 - val_categorical_accuracy: 0.8489\n",
            "Epoch 3/3\n",
            "49/49 [==============================] - 61s 1s/step - loss: 0.2178 - categorical_accuracy: 0.9256 - val_loss: 0.5075 - val_categorical_accuracy: 0.8566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9cf59572b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGSNH0THX8sV",
        "outputId": "6cd9f89e-2abc-4918-f786-dbdd031f6835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(val_generator)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 36s 3s/step - loss: 0.4126 - categorical_accuracy: 0.8822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4126453995704651, 0.8822023272514343]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghn0JOxbjcyh"
      },
      "source": [
        "model.fit(\n",
        "        train_generator,\n",
        "        initial_epoch=10,\n",
        "        epochs = 25,\n",
        "        validation_data=val_generator, callbacks=[checkpoint, checkpoint_best]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YCK1lbGTRr4"
      },
      "source": [
        "model.save(\"/content/drive/My Drive/model_best.h5\")"
      ],
      "execution_count": 51,
      "outputs": []
    }
  ]
}